{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7LP_O-psQAvA"
      },
      "source": [
        "# HSR Time To Prediction Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code for this file is mostly the same as the `Time To Prediciton Evaluation.ipynb`. This file contains the cells and code for evaluating the HSR dataset, which was large and needed to be broken down for effiency."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d0yrXlYiPpqL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-26 22:50:54.816358: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-06-26 22:50:55.275122: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-06-26 22:50:55.280399: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-26 22:50:57.688294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras import metrics\n",
        "from matplotlib import pyplot\n",
        "# from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "# %matplotlib notebook\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "import pprint\n",
        "from scipy import interpolate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yWQoJShQcP5a"
      },
      "outputs": [],
      "source": [
        "# Adding a raise exception for clean execution exit from a cell\n",
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GkdEHh9dZypG"
      },
      "source": [
        "## Loading up the model and setting up functions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xCs3WvQKsw0k"
      },
      "source": [
        "Load model according to window size"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uncomment the `model_url` line and the `wget` line in order to get the necessary model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMeDdnQhZ61C",
        "outputId": "b746004f-534f-4470-8e94-09d3ef659cf0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-26 22:51:07.420350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-06-26 22:51:07.425130: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-06-26 22:51:07.427861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-06-26 22:51:07.913389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-06-26 22:51:07.918207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-06-26 22:51:07.920484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        }
      ],
      "source": [
        "WINDOW_SIZE = 6\n",
        "\n",
        "HSR_datasets = [\"HSR_Extended_4_0\"]\n",
        "\n",
        "# model_url = \"https://anonymous.4open.science/api/repo/EdgeCatBSPDataset-1840/file/models/model_WS\" + str(WINDOW_SIZE) + \".h5\"\n",
        "# print(model_url)\n",
        "\n",
        "# !wget {model_url} -O \"model.h5\"\n",
        "\n",
        "model_eval = load_model(\"/home/mango/Projects/EDGECAT/CONEXT_EDGECAT_LOCAL/model.h5\")\n",
        "window_size = WINDOW_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U6NAryoMXIQI"
      },
      "outputs": [],
      "source": [
        "# HELPER FUNCTION DECLARATIONS\n",
        "\n",
        "# Helper function to convert string to timestamp\n",
        "def string_to_datetime_incp(timestamp):\n",
        "  return float(timestamp)\n",
        "\n",
        "\n",
        "# Helper function to convert strings into datetime objects\n",
        "def string_to_datetime(timestamp_str):\n",
        "    try:\n",
        "        time_b = datetime.strptime(timestamp_str, \"%Y-%m-%d %X.%f\")\n",
        "    except:\n",
        "        time_b = datetime.strptime(timestamp_str, \"%Y-%m-%d %X\")\n",
        "    return time_b\n",
        "\n",
        "\n",
        "# This function extracts the rsrp, rsrq and labels, along with assigning the specific dataframe a \"time to prediction\"\n",
        "def add_to_df_wts(filepath, window_size):\n",
        "  df = pd.read_csv(filepath)\n",
        "  # df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "\n",
        "  entries = []\n",
        "\n",
        "  # Getting timestamp for handover (or at least as close to it as possible)\n",
        "  last_entry = df.iloc[-1]\n",
        "  last_entry_ts = last_entry[\"timestamp\"]\n",
        "  ho_ts_datetime = string_to_datetime(last_entry_ts)\n",
        "\n",
        "  if df.shape[0] >= window_size:\n",
        "    for i in range(0, df.shape[0]-window_size):\n",
        "      # Extracting the last timestamp for this window\n",
        "      last_window_entry = df.iloc[i+window_size]\n",
        "      last_window_ts = last_window_entry[\"timestamp\"]\n",
        "      lw_ts_dt = string_to_datetime(last_window_ts) # last window timestamp datetime object\n",
        "\n",
        "      # Calculating time to handover and adding it to ttp\n",
        "      tth = ho_ts_datetime - lw_ts_dt # time to handover\n",
        "      tth_seconds = tth.total_seconds()\n",
        "\n",
        "      # Extracting the rest\n",
        "      temp = df.iloc[i:i+window_size]\n",
        "      rsrp = temp[\"rsrp\"]\n",
        "      rsrq = temp[\"rsrq\"]\n",
        "      rsrp_raw = temp[\"rsrp_raw\"]\n",
        "      rsrq_raw = temp[\"rsrq_raw\"]\n",
        "      label = df.iloc[i]\n",
        "      label = label[\"label\"]\n",
        "\n",
        "      entry = []\n",
        "      entry.append(rsrp)\n",
        "      entry.append(rsrq)\n",
        "      entry.append(label)\n",
        "      entry.append(tth_seconds)\n",
        "      entry.append(rsrp_raw)\n",
        "      entry.append(rsrq_raw)\n",
        "\n",
        "      entries.append(entry)\n",
        "\n",
        "    return entries\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "# This function extracts the rsrp, rsrq and labels, along with assigning the specific dataframe a \"time to prediction\"\n",
        "def add_to_df_wts_incp(filepath, window_size):\n",
        "  df = pd.read_csv(filepath)\n",
        "  # df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "\n",
        "  entries = []\n",
        "\n",
        "  # Getting timestamp for handover (or at least as close to it as possible)\n",
        "  last_entry = df.iloc[-1]\n",
        "  last_entry_ts = last_entry[\"timestamp\"]\n",
        "  ho_ts_datetime = string_to_datetime_incp(last_entry_ts)\n",
        "\n",
        "  if df.shape[0] >= window_size:\n",
        "    for i in range(0, df.shape[0]-window_size):\n",
        "      # Extracting the last timestamp for this window\n",
        "      last_window_entry = df.iloc[i+window_size]\n",
        "      last_window_ts = last_window_entry[\"timestamp\"]\n",
        "      lw_ts_dt = string_to_datetime_incp(last_window_ts) # last window timestamp datetime object\n",
        "\n",
        "      # Calculating time to handover and adding it to ttp\n",
        "      tth = ho_ts_datetime - lw_ts_dt # time to handover\n",
        "      # tth_seconds = tth.total_seconds()\n",
        "      tth_seconds = tth\n",
        "\n",
        "      # Extracting the rest\n",
        "      temp = df.iloc[i:i+window_size]\n",
        "      rsrp = temp[\"rsrp\"]\n",
        "      rsrq = temp[\"rsrq\"]\n",
        "      rsrp_raw = temp[\"rsrp_raw\"]\n",
        "      rsrq_raw = temp[\"rsrq_raw\"]\n",
        "      label = df.iloc[i]\n",
        "      label = label[\"label\"]\n",
        "\n",
        "      entry = []\n",
        "      entry.append(rsrp)\n",
        "      entry.append(rsrq)\n",
        "      entry.append(label)\n",
        "      entry.append(tth_seconds)\n",
        "      entry.append(rsrp_raw)\n",
        "      entry.append(rsrq_raw)\n",
        "\n",
        "      entries.append(entry)\n",
        "\n",
        "    return entries\n",
        "\n",
        "  return\n",
        "\n",
        "# Function to detect if there are no \"target\" entries in here\n",
        "def check_valid(sequence_dict, key):\n",
        "  ho_event_list = sequence_dict[key]\n",
        "  for i, base_station_entries in enumerate(ho_event_list):\n",
        "    # each base station contains a sequence of measurements at that point for this specific base station\n",
        "    if base_station_entries != [] and base_station_entries is not None:\n",
        "      label = sequence_dict[key][i][0][2]\n",
        "      # print(sequence_dict[key][i][0][2])\n",
        "      if label == 1:\n",
        "        return True\n",
        "  return False\n",
        "\n",
        "# Helper function to check if the current handover event is valid to be used for evaluation\n",
        "def check_valid_2(sd, key):\n",
        "  ho_event_list = sd[key]\n",
        "  for i, base_station_entries in enumerate(ho_event_list):\n",
        "    # each base station contains a sequence of measurements at that point for this specific base station\n",
        "    if base_station_entries != [] and base_station_entries is not None:\n",
        "      label = sd[key][i][0][2]\n",
        "      if label == 1:\n",
        "        return True\n",
        "  return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IYhagW1pHRpO"
      },
      "outputs": [],
      "source": [
        "# Helper function for loading up dataset:\n",
        "def load_dataset(datasets_list, WINDOW_SIZE):\n",
        "  # HSR_datasets is a placeholder variable.\n",
        "  sequence_dict = {}\n",
        "\n",
        "  ho_event_no = 0 # This counter keeps track of which handover event we have reached\n",
        "  for master_f in datasets_list:\n",
        "    dataset_folders = os.listdir(master_f)\n",
        "    for folder in dataset_folders:\n",
        "      folder_path = master_f + \"/\" + folder\n",
        "      files = os.listdir(folder_path)\n",
        "      ho_event_no += 1\n",
        "      curr_hoevent_entries = [] # list containing all the data for the current handover event\n",
        "      for f in files:\n",
        "        filepath = folder_path + \"/\" + f\n",
        "        entries = add_to_df_wts(filepath, window_size)\n",
        "        curr_hoevent_entries.append(entries)\n",
        "      sequence_dict[ho_event_no] = curr_hoevent_entries\n",
        "\n",
        "  sequence_dict_orig = sequence_dict.copy()\n",
        "\n",
        "  for key in sequence_dict.keys():\n",
        "    ho_event_list = sequence_dict[key]\n",
        "    for i1, entry in enumerate(ho_event_list):\n",
        "      if entry is not None:\n",
        "        for i2, subentry in enumerate(entry):\n",
        "          if subentry[2] == \"not_target\":\n",
        "            sequence_dict[key][i1][i2][2] = 0\n",
        "          else:\n",
        "            sequence_dict[key][i1][i2][2] = 1\n",
        "\n",
        "  sequence_dict_renamed = sequence_dict.copy()\n",
        "\n",
        "  sequence_dict = sequence_dict_orig.copy()\n",
        "\n",
        "  # Using minmax scaling to bring our features between 0 and 1\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "  rsrp_list = []\n",
        "  rsrq_list = []\n",
        "  rsrp_raws_list = []\n",
        "  rsrq_raws_list = []\n",
        "  labels = []\n",
        "\n",
        "  for key in sequence_dict.keys():\n",
        "    ho_event_list = sequence_dict[key]\n",
        "    if check_valid(sequence_dict, key):\n",
        "      for i1, entry in enumerate(ho_event_list):\n",
        "        if entry is not None:\n",
        "          for i2, subentry in enumerate(entry):\n",
        "            req_idx = len(rsrp_list)\n",
        "            rsrp = np.array(sequence_dict[key][i1][i2][0])\n",
        "            rsrq = np.array(sequence_dict[key][i1][i2][1])\n",
        "            label = np.array(sequence_dict[key][i1][i2][2])\n",
        "            rsrp_raws = np.array(sequence_dict[key][i1][i2][4])\n",
        "            rsrq_raws = np.array(sequence_dict[key][i1][i2][5])\n",
        "            rsrp_list.append(rsrp)\n",
        "            rsrq_list.append(rsrq)\n",
        "            rsrp_raws_list.append(rsrp_raws)\n",
        "            rsrq_raws_list.append(rsrq_raws)\n",
        "            labels.append(label)\n",
        "            sequence_dict[key][i1][i2][0] = req_idx\n",
        "            sequence_dict[key][i1][i2][1] = req_idx\n",
        "            sequence_dict[key][i1][i2][4] = req_idx\n",
        "            sequence_dict[key][i1][i2][5] = req_idx\n",
        "            # sequence_dict[key][i1][i2][2] = req_idx\n",
        "\n",
        "  rsrp_tts = scaler.fit_transform(rsrp_list)\n",
        "  rsrq_tts = scaler.fit_transform(rsrq_list)\n",
        "  rsrp_raws_tts = scaler.fit_transform(rsrp_raws_list)\n",
        "  rsrq_raws_tts = scaler.fit_transform(rsrq_raws_list)\n",
        "\n",
        "  # Combining features\n",
        "  HSR_features = np.stack([rsrp_tts, rsrq_tts, rsrp_raws_tts, rsrq_raws_tts], axis=2)\n",
        "\n",
        "  # Reshaping label data\n",
        "  HSR_labels = np.reshape(labels, (len(labels),1))\n",
        "\n",
        "  return HSR_features, HSR_labels, sequence_dict, sequence_dict_orig\n",
        "\n",
        "# Helper function specifically for loading the INCP dataset, which has a slightly different format (both in terms of data types and column titles)\n",
        "def load_incp_dataset(WINDOW_SIZE):\n",
        "  # Iterate over the files and populate sequence_dict\n",
        "  dataset_master_folders = [\"icnp-dataset/ATT\", \"icnp-dataset/TMobile\"]\n",
        "\n",
        "  sequence_dict = {}\n",
        "\n",
        "  ho_event_no = 0 # This counter keeps track of which handover event we have reached\n",
        "  for master_f in dataset_master_folders:\n",
        "    dataset_folders = os.listdir(master_f)\n",
        "    for folder in dataset_folders:\n",
        "      folder_path = master_f + \"/\" + folder\n",
        "      files = os.listdir(folder_path)\n",
        "      ho_event_no += 1\n",
        "      curr_hoevent_entries = [] # list containing all the data for the current handover event\n",
        "      for f in files:\n",
        "        filepath = folder_path + \"/\" + f\n",
        "        entries = add_to_df_wts_incp(filepath, WINDOW_SIZE)\n",
        "        curr_hoevent_entries.append(entries)\n",
        "      sequence_dict[ho_event_no] = curr_hoevent_entries\n",
        "\n",
        "  sequence_dict_orig = sequence_dict.copy()\n",
        "\n",
        "  # Renaming the labels and converting into required data types\n",
        "\n",
        "  # sequence_dict = sequence_dict_orig.copy()\n",
        "\n",
        "  for key in sequence_dict.keys():\n",
        "    ho_event_list = sequence_dict[key]\n",
        "    for i1, entry in enumerate(ho_event_list):\n",
        "      if entry is not None:\n",
        "        for i2, subentry in enumerate(entry):\n",
        "          if subentry[2] == \"not_target\":\n",
        "            sequence_dict[key][i1][i2][2] = 0\n",
        "          else:\n",
        "            sequence_dict[key][i1][i2][2] = 1\n",
        "\n",
        "  sequence_dict_renamed = sequence_dict.copy()\n",
        "\n",
        "  sequence_dict = sequence_dict_orig.copy()\n",
        "\n",
        "  # Using minmax scaling to bring our features between 0 and 1\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "  rsrp_list = []\n",
        "  rsrq_list = []\n",
        "  rsrp_raws_list = []\n",
        "  rsrq_raws_list = []\n",
        "  labels = []\n",
        "\n",
        "  for key in sequence_dict.keys():\n",
        "    ho_event_list = sequence_dict[key]\n",
        "    if check_valid(sequence_dict, key):\n",
        "      for i1, entry in enumerate(ho_event_list):\n",
        "        if entry is not None:\n",
        "          for i2, subentry in enumerate(entry):\n",
        "            req_idx = len(rsrp_list)\n",
        "            rsrp = np.array(sequence_dict[key][i1][i2][0])\n",
        "            rsrq = np.array(sequence_dict[key][i1][i2][1])\n",
        "            label = np.array(sequence_dict[key][i1][i2][2])\n",
        "            rsrp_raws = np.array(sequence_dict[key][i1][i2][4])\n",
        "            rsrq_raws = np.array(sequence_dict[key][i1][i2][5])\n",
        "            rsrp_list.append(rsrp)\n",
        "            rsrq_list.append(rsrq)\n",
        "            rsrp_raws_list.append(rsrp_raws)\n",
        "            rsrq_raws_list.append(rsrq_raws)\n",
        "            labels.append(label)\n",
        "            sequence_dict[key][i1][i2][0] = req_idx\n",
        "            sequence_dict[key][i1][i2][1] = req_idx\n",
        "            sequence_dict[key][i1][i2][4] = req_idx\n",
        "            sequence_dict[key][i1][i2][5] = req_idx\n",
        "            # sequence_dict[key][i1][i2][2] = req_idx\n",
        "\n",
        "  rsrp_tts = scaler.fit_transform(rsrp_list)\n",
        "  rsrq_tts = scaler.fit_transform(rsrq_list)\n",
        "  rsrp_raws_tts = scaler.fit_transform(rsrp_raws_list)\n",
        "  rsrq_raws_tts = scaler.fit_transform(rsrq_raws_list)\n",
        "\n",
        "  # Combining features\n",
        "  features = np.stack([rsrp_tts, rsrq_tts, rsrp_raws_tts, rsrq_raws_tts], axis=2)\n",
        "\n",
        "  # Reshaping label data\n",
        "  labels = np.reshape(labels, (len(labels),1))\n",
        "\n",
        "  return features, labels, sequence_dict, sequence_dict_orig\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MA3EQXaKcybW"
      },
      "source": [
        "## Padding in feature vector generation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bBUB3-NGsr1R"
      },
      "source": [
        "### Padding Helper Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kzxWMQuI47AP"
      },
      "outputs": [],
      "source": [
        "# helper function that checks whether or not the current df will require padding\n",
        "def padding_condition_check(df, window_size, handover_ts):\n",
        "  # fails basic length check\n",
        "  if len(df) < window_size:\n",
        "    return True\n",
        "  # calculating time diff\n",
        "  window1 = df[0:window_size]\n",
        "  last_entry = df.iloc[window_size-1]\n",
        "  last_entry_ts = last_entry[\"timestamp\"]\n",
        "  le_ts_datetime = string_to_datetime(last_entry_ts)\n",
        "  ho_diff = handover_ts - le_ts_datetime\n",
        "  ho_diff_seconds = ho_diff.total_seconds()\n",
        "  # fails time check\n",
        "  if ho_diff_seconds <= 0.1:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "# helper function to extract entries from a dataframe and append them to the \"entries\" list\n",
        "def extract_entries(df, window_size, ho_ts_datetime):\n",
        "  entries = []\n",
        "  for i in range(df.shape[0] - window_size + 1):\n",
        "    df_slice = df.iloc[i:i+window_size]\n",
        "    # Extracting the last timestamp for this window\n",
        "    last_window_entry = df.iloc[i+window_size-1]\n",
        "    last_window_ts = last_window_entry[\"timestamp\"]\n",
        "    lw_ts_dt = string_to_datetime(last_window_ts) # last window timestamp datetime object\n",
        "\n",
        "    # Calculating time to handover and adding it to ttp\n",
        "    tth = ho_ts_datetime - lw_ts_dt # time to handover\n",
        "    tth_seconds = tth.total_seconds()\n",
        "\n",
        "    rsrp = df_slice[\"rsrp\"]\n",
        "    rsrq = df_slice[\"rsrq\"]\n",
        "    rsrp_raw = df_slice[\"rsrp_raw\"]\n",
        "    rsrq_raw = df_slice[\"rsrq_raw\"]\n",
        "    label = df.iloc[i]\n",
        "    label = label[\"label\"]\n",
        "\n",
        "    entry = []\n",
        "    entry.append(rsrp)\n",
        "    entry.append(rsrq)\n",
        "    entry.append(label)\n",
        "    entry.append(tth_seconds)\n",
        "    entry.append(rsrp_raw)\n",
        "    entry.append(rsrq_raw)\n",
        "\n",
        "    entries.append(entry)\n",
        "\n",
        "  return entries\n",
        "\n",
        "# helper function that returns the entries list as it would have appeared in regular execution\n",
        "def regular_extension(df, window_size):\n",
        "  entries = []\n",
        "  # Getting timestamp for handover (or at least as close to it as possible)\n",
        "  last_entry = df.iloc[-1]\n",
        "  last_entry_ts = last_entry[\"timestamp\"]\n",
        "  ho_ts_datetime = string_to_datetime(last_entry_ts)\n",
        "  if df.shape[0] >= window_size:\n",
        "    for i in range(0, df.shape[0]-window_size):\n",
        "      # Extracting the last timestamp for this window\n",
        "      last_window_entry = df.iloc[i+window_size]\n",
        "      last_window_ts = last_window_entry[\"timestamp\"]\n",
        "      lw_ts_dt = string_to_datetime(last_window_ts) # last window timestamp datetime object\n",
        "\n",
        "      # Calculating time to handover and adding it to ttp\n",
        "      tth = ho_ts_datetime - lw_ts_dt # time to handover\n",
        "      tth_seconds = tth.total_seconds()\n",
        "\n",
        "      # Extracting the rest\n",
        "      temp = df.iloc[i:i+window_size]\n",
        "      rsrp = temp[\"rsrp\"]\n",
        "      rsrq = temp[\"rsrq\"]\n",
        "      rsrp_raw = temp[\"rsrp_raw\"]\n",
        "      rsrq_raw = temp[\"rsrq_raw\"]\n",
        "      label = df.iloc[i]\n",
        "      label = label[\"label\"]\n",
        "\n",
        "      entry = []\n",
        "      entry.append(rsrp)\n",
        "      entry.append(rsrq)\n",
        "      entry.append(label)\n",
        "      entry.append(tth_seconds)\n",
        "      entry.append(rsrp_raw)\n",
        "      entry.append(rsrq_raw)\n",
        "\n",
        "      entries.append(entry)\n",
        "\n",
        "  return entries\n",
        "\n",
        "# dataframe containing features is passed as argument to this function along with the window size\n",
        "# helper function that returns a list of entries for the input dataframe by performing backward padding: i.e., appending the last value to the end as many times as needed\n",
        "def backward_padding(df, window_size):\n",
        "  entries = []\n",
        "  last_entry = df.iloc[-1]\n",
        "  last_entry_ts = last_entry[\"timestamp\"]\n",
        "  ho_ts_datetime = string_to_datetime(last_entry_ts)\n",
        "\n",
        "  # simple padding in case the window is simply not long enough\n",
        "  if len(df) < window_size:\n",
        "    for i in range(len(df)):\n",
        "      # index to check => len(df)-1-i\n",
        "      df_temp = df[0:i+1]\n",
        "      num_reps = window_size - 1 - i # number of times the entry needs to be repeated\n",
        "      to_repeat = df.iloc[i]\n",
        "      for i in range(num_reps):\n",
        "        df_temp = pd.concat([df_temp, to_repeat.to_frame().T], ignore_index = True)\n",
        "      entries_curr_iter = extract_entries(df_temp, window_size, ho_ts_datetime) # entries from the current iteration\n",
        "      entries.extend(entries_curr_iter)\n",
        "\n",
        "  # timer check\n",
        "  else:\n",
        "    for i in range(df.shape[0]-1):\n",
        "      # this check ensure that we have all the measurements we can get till this point\n",
        "      # hence, this iterable should not go past window_size\n",
        "      if i == window_size:\n",
        "        break\n",
        "\n",
        "      df_temp = df[0:i+1]\n",
        "      num_reps = window_size - 1 - i # number of times the entry needs to be repeated\n",
        "      to_repeat = df.iloc[i]\n",
        "      for i in range(num_reps):\n",
        "        df_temp = pd.concat([df_temp, to_repeat.to_frame().T], ignore_index = True)\n",
        "      entries_curr_iter = extract_entries(df_temp, window_size, ho_ts_datetime)\n",
        "      entries.extend(entries_curr_iter)\n",
        "\n",
        "    # also need regular extension\n",
        "    reg_extension_entries = regular_extension(df, window_size)\n",
        "    entries.extend(reg_extension_entries)\n",
        "\n",
        "  return entries\n",
        "\n",
        "# extracts \"entries\" from a file, which is a list of lists containing feature vectors\n",
        "def add_to_entries(filepath, window_size):\n",
        "  df = pd.read_csv(filepath)\n",
        "  # df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "\n",
        "  ho_entry = df.iloc[-1]\n",
        "  ho_entry_ts = ho_entry[\"timestamp\"]\n",
        "  ho_ts_datetime = string_to_datetime(ho_entry_ts)\n",
        "\n",
        "  entries = []\n",
        "\n",
        "  if padding_condition_check(df, window_size, ho_ts_datetime):\n",
        "    # make longer vectors using padding\n",
        "    # COMMENT THIS LINE OUT TO USE WHICHEVER PADDING METHOD YOU WANT TO TEST\n",
        "    entries = backward_padding(df, window_size)\n",
        "    # entries = le_padding(df, window_size)\n",
        "    return entries\n",
        "  else:\n",
        "    # normal execution (without padding)\n",
        "    entries = regular_extension(df, window_size)\n",
        "    return entries"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear Extrapolation padding implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.5 2.5 3.5 4.5 5.5 6.5]\n"
          ]
        }
      ],
      "source": [
        "from scipy import interpolate\n",
        "input_arr = np.array([1.5,2.5])\n",
        "len_input_arr = len(input_arr)\n",
        "x_arr = np.arange(0, len(input_arr))\n",
        "f = interpolate.interp1d(x_arr, input_arr, fill_value='extrapolate')\n",
        "for i in range(len_input_arr, 6):\n",
        "    input_arr = np.append(input_arr, f(i))\n",
        "print(input_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# helper function to perform linear extrapolation on a list\n",
        "def le_meas_list(input, window_size):\n",
        "    input_arr = np.array(input)\n",
        "    input_arr_len = len(input_arr) # we save this here to use later as an iterator\n",
        "    if input_arr_len == 1:\n",
        "        input_arr = np.repeat(input_arr[0], window_size)\n",
        "    else:\n",
        "        x_arr = np.arange(0, input_arr_len)\n",
        "        f = interpolate.interp1d(x_arr, input_arr, fill_value='extrapolate')\n",
        "        for i in range(input_arr_len, window_size):\n",
        "            input_arr = np.append(input_arr, f(i))\n",
        "    return input_arr\n",
        "\n",
        "# helper function that performs linear extrapolation padding to a dataframe of entries\n",
        "def le_df_padder(df, window_size):\n",
        "    final_df = pd.DataFrame()\n",
        "    timestamps = list(df[\"timestamp\"])\n",
        "    for i in range(window_size - len(df)):\n",
        "        timestamps.append(timestamps[-1])\n",
        "    final_df[\"timestamp\"] = timestamps\n",
        "    final_df[\"rsrp\"] = le_meas_list(list(df[\"rsrp\"]), window_size)\n",
        "    final_df[\"rsrq\"] = le_meas_list(list(df[\"rsrq\"]), window_size)\n",
        "    final_df[\"rsrp_raw\"] = le_meas_list(list(df[\"rsrp_raw\"]), window_size)\n",
        "    final_df[\"rsrq_raw\"] = le_meas_list(list(df[\"rsrq_raw\"]), window_size)\n",
        "    final_df[\"label\"] = [df.iloc[0][\"label\"] for i in range(window_size)]\n",
        "\n",
        "    return final_df\n",
        "\n",
        "## helper function that performs linear extrapolation padding, i.e. extrapolating the values based on a linear gradient so far\n",
        "def le_padding(df, window_size):\n",
        "    entries = []\n",
        "    last_entry = df.iloc[-1]\n",
        "    last_entry_ts = last_entry[\"timestamp\"]\n",
        "    ho_ts_datetime = string_to_datetime(last_entry_ts)\n",
        "\n",
        "    # if not long enough\n",
        "    if len(df) < window_size:\n",
        "        for i in range(len(df)):\n",
        "            temp_df = df.iloc[0:i+1]\n",
        "            temp_df = le_df_padder(temp_df, window_size)\n",
        "            entries_curr_iter = extract_entries(temp_df, window_size, ho_ts_datetime)\n",
        "            entries.extend(entries_curr_iter)\n",
        "\n",
        "    # if problem is time\n",
        "    else:\n",
        "        for i in range(df.shape[0]-1):\n",
        "            # this check ensure that we have all the measurements we can get till this point\n",
        "            # hence, this iterable should not go past window_size\n",
        "            if i == window_size:\n",
        "                break\n",
        "            temp_df = df[0:i+1]\n",
        "            temp_df = le_df_padder(temp_df, window_size)\n",
        "            entries_curr_iter = extract_entries(temp_df, window_size, ho_ts_datetime)\n",
        "            entries.extend(entries_curr_iter)\n",
        "            \n",
        "        # also need regular extension\n",
        "        reg_extension_entries = regular_extension(df, window_size)\n",
        "        entries.extend(reg_extension_entries)\n",
        "\n",
        "    return entries"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padding Main Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MVlRGTg4_TDY"
      },
      "outputs": [],
      "source": [
        "# rsrp_list = []\n",
        "# rsrq_list = []\n",
        "# rsrp_raws_list = []\n",
        "# rsrq_raws_list = []\n",
        "# labels = []\n",
        "\n",
        "# Helper function for loading up dataset:\n",
        "def load_dataset_padding(datasets_list, WINDOW_SIZE):\n",
        "  # HSR_datasets is a placeholder variable.\n",
        "  sequence_dict = {}\n",
        "\n",
        "  diff_count = 0\n",
        "\n",
        "  ho_event_no = 0 # This counter keeps track of which handover event we have reached\n",
        "  for master_f in datasets_list:\n",
        "    dataset_folders = os.listdir(master_f)\n",
        "    for folder in dataset_folders:\n",
        "      folder_path = master_f + \"/\" + folder\n",
        "      files = os.listdir(folder_path)\n",
        "      ho_event_no += 1\n",
        "      curr_hoevent_entries = [] # list containing all the data for the current handover event\n",
        "      for f in files:\n",
        "        filepath = folder_path + \"/\" + f\n",
        "        len_entries = 0\n",
        "        len_entries2 = 0\n",
        "        entries = add_to_entries(filepath, WINDOW_SIZE)\n",
        "        curr_hoevent_entries.append(entries)\n",
        "      sequence_dict[ho_event_no] = curr_hoevent_entries\n",
        "\n",
        "  sequence_dict_orig = sequence_dict.copy()\n",
        "\n",
        "  print(\"DIFF COUNT CHECK:\", diff_count)\n",
        "\n",
        "  for key in sequence_dict.keys():\n",
        "    ho_event_list = sequence_dict[key]\n",
        "    for i1, entry in enumerate(ho_event_list):\n",
        "      if entry is not None:\n",
        "        for i2, subentry in enumerate(entry):\n",
        "          if subentry[2] == \"not_target\":\n",
        "            sequence_dict[key][i1][i2][2] = 0\n",
        "          else:\n",
        "            sequence_dict[key][i1][i2][2] = 1\n",
        "\n",
        "  sequence_dict_renamed = sequence_dict.copy()\n",
        "\n",
        "  sequence_dict = sequence_dict_orig.copy()\n",
        "\n",
        "  # Using minmax scaling to bring our features between 0 and 1\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "  rsrp_list = []\n",
        "  rsrq_list = []\n",
        "  rsrp_raws_list = []\n",
        "  rsrq_raws_list = []\n",
        "  labels = []\n",
        "\n",
        "  for key in sequence_dict.keys():\n",
        "    ho_event_list = sequence_dict[key]\n",
        "    if check_valid(sequence_dict, key):\n",
        "      for i1, entry in enumerate(ho_event_list):\n",
        "        if entry is not None:\n",
        "          for i2, subentry in enumerate(entry):\n",
        "            req_idx = len(rsrp_list)\n",
        "            rsrp = np.array(sequence_dict[key][i1][i2][0])\n",
        "            rsrq = np.array(sequence_dict[key][i1][i2][1])\n",
        "            label = np.array(sequence_dict[key][i1][i2][2])\n",
        "            rsrp_raws = np.array(sequence_dict[key][i1][i2][4])\n",
        "            rsrq_raws = np.array(sequence_dict[key][i1][i2][5])\n",
        "            rsrp_list.append(rsrp)\n",
        "            rsrq_list.append(rsrq)\n",
        "            rsrp_raws_list.append(rsrp_raws)\n",
        "            rsrq_raws_list.append(rsrq_raws)\n",
        "            labels.append(label)\n",
        "            sequence_dict[key][i1][i2][0] = req_idx\n",
        "            sequence_dict[key][i1][i2][1] = req_idx\n",
        "            sequence_dict[key][i1][i2][4] = req_idx\n",
        "            sequence_dict[key][i1][i2][5] = req_idx\n",
        "            # sequence_dict[key][i1][i2][2] = req_idx\n",
        "\n",
        "  # print(rsrp_list)\n",
        "\n",
        "  rsrp_tts = scaler.fit_transform(rsrp_list)\n",
        "  rsrq_tts = scaler.fit_transform(rsrq_list)\n",
        "  rsrp_raws_tts = scaler.fit_transform(rsrp_raws_list)\n",
        "  rsrq_raws_tts = scaler.fit_transform(rsrq_raws_list)\n",
        "\n",
        "  # Combining features\n",
        "  HSR_features = np.stack([rsrp_tts, rsrq_tts, rsrp_raws_tts, rsrq_raws_tts], axis=2)\n",
        "\n",
        "  # Reshaping label data\n",
        "  HSR_labels = np.reshape(labels, (len(labels),1))\n",
        "\n",
        "  return HSR_features, HSR_labels, sequence_dict, sequence_dict_orig"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqu0oZ6QvtLT"
      },
      "source": [
        "# BASE STATION PREDICTION"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xfY5USf2uJrJ"
      },
      "source": [
        "## Evaluating for Top N Base Stations predicted"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vu7wYFOw3Ln"
      },
      "source": [
        "## Setting up helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AbE4gL449lMN"
      },
      "outputs": [],
      "source": [
        "# streamlining pipeline by encompassing in functions\n",
        "\n",
        "# helper function that predicts handoever events, and returns a dictionary which maps each handover event to the time at which the handover event is predicted\n",
        "def predict_HO_events(input_features, input_labels, model_eval, sequence_dict, sequence_dict_orig, sequence_dict_checker):\n",
        "  # TODO: add exact variable type information for all the parameters\n",
        "  # input_features : list of all input features for which predictions have to be made\n",
        "  # input_labels : list of labels\n",
        "  # model_eval : keras model being used for evaluation\n",
        "  # sequence_dict : dictionary keeping track of a measurement and result pairing. i.e., which index in the resulting matrix refers to a specific measurement\n",
        "\n",
        "  predictions = model_eval.predict(input_features)\n",
        "  bool_predictions = (predictions > 0.37)\n",
        "  cm = confusion_matrix(input_labels, bool_predictions)\n",
        "  tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "  earliest_HO_times = {}\n",
        "  TOTAL_VALID_EVENTS = 0\n",
        "  FAILED_PREDICTING = 0\n",
        "\n",
        "  # Predicting handover events\n",
        "  for HO_COUNT, key in enumerate(sequence_dict.keys()):\n",
        "    # variable that checks if the handover for the current event has been predicted\n",
        "    HO_PREDICTED = False\n",
        "    ho_event_list = sequence_dict[key]\n",
        "    if check_valid_2(sequence_dict_checker, key):\n",
        "      TOTAL_VALID_EVENTS += 1\n",
        "      for i1, entry in enumerate(ho_event_list): # check for the current HO event\n",
        "        if entry is not None:\n",
        "          for i2, subentry in enumerate(entry): # this inner loop checks everything for a single base station\n",
        "            req_idx = sequence_dict[key][i1][i2][0]\n",
        "            label = input_labels[req_idx][0]\n",
        "            curr_ts = sequence_dict[key][i1][i2][3]\n",
        "            prediction = bool_predictions[req_idx]\n",
        "            if prediction == 1: # if a handover is predicted\n",
        "              HO_PREDICTED = True\n",
        "              if key in earliest_HO_times:\n",
        "                if curr_ts > earliest_HO_times[key]:\n",
        "                  earliest_HO_times[key] = curr_ts\n",
        "              else:\n",
        "                earliest_HO_times[key] = curr_ts\n",
        "      if HO_PREDICTED == False:\n",
        "        FAILED_PREDICTING += 1\n",
        "\n",
        "  return earliest_HO_times, TOTAL_VALID_EVENTS, FAILED_PREDICTING, predictions, bool_predictions\n",
        "\n",
        "# helper function that gets confidence values/probabilities\n",
        "def get_probabilities(sequence_dict, sequence_dict_orig, sequence_dict_checker, actual_labels, predictions_probs, predictions_bools, earliest_HO_times):\n",
        "  HO_to_ts_dict = {}\n",
        "  HO_label_dict = {}\n",
        "\n",
        "  # First iteration should be about going through each base station and getting confidence values for each BS\n",
        "  for HO_COUNT, key in enumerate(sequence_dict.keys()): # Each iteration refers to each Handover event\n",
        "    ho_event_list = sequence_dict[key]\n",
        "    HO_to_ts_dict[key] = {}\n",
        "    if check_valid_2(sequence_dict_checker, key): # Check if this HO event is usable (is the data entry clean enough to be usable?)\n",
        "      for i1, entry in enumerate(ho_event_list): # i1 can be used to identify the base station\n",
        "        if entry is not None:\n",
        "          HO_to_ts_dict[key][i1] = {}\n",
        "          for i2, subentry in enumerate(entry):\n",
        "            req_idx = sequence_dict[key][i1][i2][0]\n",
        "            label = actual_labels[req_idx][0]\n",
        "            curr_ts = sequence_dict[key][i1][i2][3]\n",
        "            prediction = predictions_bools[req_idx]\n",
        "            prediction_probability = predictions_probs[req_idx][0]\n",
        "            if label == 1:\n",
        "              HO_label_dict[key] = i1\n",
        "            try:\n",
        "              if curr_ts <= earliest_HO_times[key]:\n",
        "                # handover prediction has happened, base station prediction can be performed\n",
        "                HO_to_ts_dict[key][i1][curr_ts] = prediction_probability\n",
        "            except:\n",
        "              # Evaluated the number of events for which HO was not predicted - add them to our evaluation\n",
        "              pass\n",
        "\n",
        "  # HO_to_ts_dict has the following structure:\n",
        "  # {handover_id : {base_station_id : {timestamp : probability}}}\n",
        "  # Number of base stations on which state will be replicated. For every handover event, we will consider the top candidates from these two base stations\n",
        "  earliest_time_BSP = [] # Number of BSP failures can be calculated as a difference in number of handover events predictions, and number of BSP earliest time predictions\n",
        "\n",
        "  # need to keep track of another pairing:\n",
        "  # {handover_id : {timestamp : {probability : base_station_id}}} => ts_prob_pairing\n",
        "  ts_prob_pairing = {}\n",
        "  # also need to keep a track of a list of sorted probabilities at each timestamp\n",
        "  # {handover_id: {timestamp : [sorted probabilities] }}\n",
        "  ts_probabilities = {}\n",
        "\n",
        "  for handover_key in HO_to_ts_dict.keys():\n",
        "    all_bs_info = HO_to_ts_dict[handover_key] # for a handover event with id = handover_key, this dict contains information of all BSes\n",
        "    ts_prob_pairing[handover_key] = {}\n",
        "    ts_probabilities[handover_key] = {}\n",
        "    for bs_id in all_bs_info.keys():\n",
        "      bs_info = all_bs_info[bs_id] # should contain information for a single base station for a single handover event\n",
        "      for ts in bs_info.keys():\n",
        "        curr_bs_ts_prob = bs_info[ts]\n",
        "        # Add pairing to keep track of which probability we are considering\n",
        "        if ts not in ts_prob_pairing[handover_key].keys():\n",
        "          ts_prob_pairing[handover_key][ts] = {}\n",
        "          ts_prob_pairing[handover_key][ts][curr_bs_ts_prob] = bs_id\n",
        "        else:\n",
        "          ts_prob_pairing[handover_key][ts][curr_bs_ts_prob] = bs_id\n",
        "        # Append to list of probabilities\n",
        "        if ts not in ts_probabilities[handover_key].keys():\n",
        "          ts_probabilities[handover_key][ts] = [curr_bs_ts_prob]\n",
        "        else:\n",
        "          ts_probabilities[handover_key][ts].append(curr_bs_ts_prob)\n",
        "          ts_probabilities[handover_key][ts] = sorted(ts_probabilities[handover_key][ts], reverse=True)\n",
        "\n",
        "  return ts_probabilities, ts_prob_pairing, HO_label_dict\n",
        "\n",
        "# helper function that returns a list with time to prediction\n",
        "def get_time_to_predictions(ts_probabilities, ts_prob_pairing, HO_label_dict, top_N):\n",
        "  # ts_probabilities => {handover_id: {timestamp : [sorted probabilities] }}\n",
        "  # ts_prob_pairing => {handover_id : {timestamp : {probability : base_station_id}}} => ts_prob_pairing\n",
        "  # HO_label_dict is a dictionary that contains the label index for each handover event\n",
        "  # top_N is a number which indicates how many BSes we intend to have as targets\n",
        "\n",
        "  HO_BSP_FAILURES = 0\n",
        "  earliest_time_BSP = []\n",
        "\n",
        "  for handover_key in ts_probabilities.keys():\n",
        "    timestamps = ts_probabilities[handover_key]\n",
        "    timestamps = sorted(timestamps, reverse=True)\n",
        "    if timestamps == []:\n",
        "      continue\n",
        "    BSP_PREDICTED = False\n",
        "    actual_label = HO_label_dict[handover_key]\n",
        "    for ts in timestamps:\n",
        "      probs = sorted(ts_probabilities[handover_key][ts], reverse=True)\n",
        "      if BSP_PREDICTED == True:\n",
        "        break\n",
        "      num_probs_to_check = min(top_N, len(ts_probabilities[handover_key][ts])) # the number of probabilities to read: this is the min of number of available BSes,\n",
        "      for i in range(num_probs_to_check):\n",
        "        if BSP_PREDICTED == True:\n",
        "          break\n",
        "        predicted_label = ts_prob_pairing[handover_key][ts][probs[i]]\n",
        "        if predicted_label == actual_label:\n",
        "          BSP_PREDICTED = True\n",
        "          earliest_time_BSP.append(ts)\n",
        "\n",
        "  return earliest_time_BSP\n",
        "\n",
        "# helper function to print out the graph\n",
        "def print_results(earliest_times, output_fname, handover_count):\n",
        "  # %matplotlib inline\n",
        "\n",
        "  # Declare num of datapoints\n",
        "  # N = len(earliest_times)\n",
        "  N = handover_count\n",
        "  print(\"Handover Count:\", N)\n",
        "\n",
        "  x = np.sort(earliest_times)\n",
        "  y = np.arange(N) / float(N)\n",
        "\n",
        "  # print(earliest_times)\n",
        "\n",
        "  # plt.xlabel(\"Earliest Time to Prediction (seconds)\")\n",
        "  # plt.ylabel(\"Probability (CDF)\")\n",
        "  # plt.title(\"CDF for Earliest Time to Prediction (Window Size = 6, Dataset=HSR)\")\n",
        "\n",
        "  # plt.plot(x,y, marker='o')\n",
        "  # plt.show()\n",
        "  # print(earliest_times)\n",
        "\n",
        "  earliest_times_df = pd.DataFrame(earliest_times)\n",
        "  print(earliest_times_df.describe())\n",
        "\n",
        "  g100 = 0\n",
        "  g200 = 0\n",
        "  g500 = 0\n",
        "  g1000 = 0\n",
        "  g90 = 0\n",
        "\n",
        "  for x in earliest_times:\n",
        "    if x >= 0.09:\n",
        "      g90 += 1\n",
        "    if x >= 0.1:\n",
        "      g100 += 1\n",
        "    if x >= 0.2:\n",
        "      g200 += 1\n",
        "    if x >= 0.5:\n",
        "      g500 += 1\n",
        "    if x >= 1:\n",
        "      g1000 += 1\n",
        "\n",
        "  print(\"100: \", g100/N * 100)\n",
        "  print(\"200: \", g200/N * 100)\n",
        "  print(\"500: \", g500/N * 100)\n",
        "  print(\"1000: \", g1000/N * 100)\n",
        "\n",
        "  with open(output_fname, \"w\") as output:\n",
        "      for item in earliest_times:\n",
        "          output.write(str(item) + \"\\n\")\n",
        "\n",
        "\n",
        "# helper function to print out the graph\n",
        "def print_results_incp(earliest_times, output_fname, handover_count):\n",
        "  # %matplotlib inline\n",
        "\n",
        "  # Declare num of datapoints\n",
        "  N = len(earliest_times)\n",
        "  # N = handover_count\n",
        "\n",
        "  # x = np.sort(earliest_times)\n",
        "  # y = np.arange(N) / float(N)\n",
        "\n",
        "  # plt.xlabel(\"Earliest Time to Prediction (seconds)\")\n",
        "  # plt.ylabel(\"Probability (CDF)\")\n",
        "  # plt.title(\"CDF for Earliest Time to Prediction (Window Size = 6, Dataset=INCP)\")\n",
        "\n",
        "  # plt.plot(x,y, marker='o')\n",
        "  # plt.show()\n",
        "\n",
        "  earliest_times_df = pd.DataFrame(earliest_times)\n",
        "  print(earliest_times_df.describe())\n",
        "\n",
        "  g100 = 0\n",
        "  g200 = 0\n",
        "  g500 = 0\n",
        "  g1000 = 0\n",
        "  g90 = 0\n",
        "\n",
        "  for x in earliest_times:\n",
        "    if x >= 0.08:\n",
        "      g90 += 1\n",
        "    if x >= 0.1:\n",
        "      g100 += 1\n",
        "    if x >= 0.2:\n",
        "      g200 += 1\n",
        "    if x >= 0.5:\n",
        "      g500 += 1\n",
        "    if x >= 1:\n",
        "      g1000 += 1\n",
        "  print(\"100: \", g100/N * 100)\n",
        "  print(\"200: \", g200/N * 100)\n",
        "  print(\"500: \", g500/N * 100)\n",
        "  print(\"1000: \", g1000/N * 100)\n",
        "\n",
        "  with open(output_fname, \"w\") as output:\n",
        "      for item in earliest_times:\n",
        "          output.write(str(item) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mXj8XG064wVF"
      },
      "outputs": [],
      "source": [
        "# putting all the above helper functions together\n",
        "def get_top_n_results(model_eval, input_features, input_labels, sequence_dict, sequence_dict_orig, sequence_dict_checker, top_N, output_fname):\n",
        "  # predicting handover events and getting relevant timestamps\n",
        "  earliest_HO_times, TOTAL_VALID_EVENTS, FAILED_PREDICTING, predictions_probs, predictions_bools = predict_HO_events(input_features, input_labels, model_eval, sequence_dict, sequence_dict_orig, sequence_dict_checker)\n",
        "  # getting relevant probability relations and pairings with handover events\n",
        "  ts_probabilities, ts_prob_pairing, HO_label_dict = get_probabilities(sequence_dict, sequence_dict_orig, sequence_dict_checker, input_labels, predictions_probs, predictions_bools, earliest_HO_times)\n",
        "  # getting a list of earliest time to predictions\n",
        "  earliest_times_BSP = get_time_to_predictions(ts_probabilities, ts_prob_pairing, HO_label_dict, top_N)\n",
        "  # generating graphs and getting the relevant results\n",
        "  print_results(earliest_times_BSP, output_fname, TOTAL_VALID_EVENTS)\n",
        "\n",
        "# putting all the above helper functions together\n",
        "def get_top_n_results_incp(model_eval, input_features, input_labels, sequence_dict, sequence_dict_orig, sequence_dict_checker, top_N, output_fname):\n",
        "  # predicting handover events and getting relevant timestamps\n",
        "  earliest_HO_times, TOTAL_VALID_EVENTS, FAILED_PREDICTING, predictions_probs, predictions_bools = predict_HO_events(input_features, input_labels, model_eval, sequence_dict, sequence_dict_orig, sequence_dict_checker)\n",
        "  # getting relevant probability relations and pairings with handover events\n",
        "  ts_probabilities, ts_prob_pairing, HO_label_dict = get_probabilities(sequence_dict, sequence_dict_orig, sequence_dict_checker, input_labels, predictions_probs, predictions_bools, earliest_HO_times)\n",
        "  # getting a list of earliest time to predictions\n",
        "  earliest_times_BSP = get_time_to_predictions(ts_probabilities, ts_prob_pairing, HO_label_dict, top_N)\n",
        "  # generating graphs and getting the relevant results\n",
        "  print_results_incp(earliest_times_BSP, output_fname, TOTAL_VALID_EVENTS)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KL8cS1KmLLRt"
      },
      "source": [
        "## Evaluating a theoretical maximum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fowvgG_8LN4p"
      },
      "outputs": [],
      "source": [
        "def max_achievable(sequence_dict, sequence_dict_checker, actual_labels):\n",
        "    best_possible = []\n",
        "\n",
        "    # extracting the best possible times from the loaded data\n",
        "    for HO_COUNT, key in enumerate(sequence_dict.keys()): # Each iteration refers to each Handover event\n",
        "        ho_event_list = sequence_dict[key]\n",
        "        if check_valid_2(sequence_dict_checker, key): # Check if this HO event is usable (is the data entry clean enough to be usable?)\n",
        "            time_noted = False\n",
        "            for i1, entry in enumerate(ho_event_list): # i1 can be used to identify the base station\n",
        "                    if entry is not None:\n",
        "                        if not time_noted:\n",
        "                            for i2, subentry in enumerate(entry):\n",
        "                                req_idx = sequence_dict[key][i1][i2][0]\n",
        "                                label = actual_labels[req_idx][0]\n",
        "                                curr_ts = sequence_dict[key][i1][i2][3]\n",
        "                                if label:\n",
        "                                    best_possible.append(curr_ts)\n",
        "                                    time_noted = True\n",
        "                                    break\n",
        "                        else:\n",
        "                            break\n",
        "    \n",
        "    # Evaluating the best possible times\n",
        "    df = pd.DataFrame(best_possible)\n",
        "    print(df.describe())\n",
        "\n",
        "    N = len(best_possible)\n",
        "    g100 = 0\n",
        "    g200 = 0\n",
        "    g500 = 0\n",
        "    g1000 = 0\n",
        "\n",
        "    for x in best_possible:\n",
        "        if x >= 0.1:\n",
        "            g100 += 1\n",
        "        if x >= 0.2:\n",
        "            g200 += 1\n",
        "        if x >= 0.5:\n",
        "            g500 += 1\n",
        "        if x >= 1:\n",
        "            g1000 += 1\n",
        "\n",
        "    print(\"100: \", g100/N * 100)\n",
        "    print(\"200: \", g200/N * 100)\n",
        "    print(\"500: \", g500/N * 100)\n",
        "    print(\"1000: \", g1000/N * 100)\n",
        "\n",
        "                            \n",
        "# max_achievable(HSR_seq_dict, HSR_seq_dict_checker, HSR_labels)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting the HSR Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the dataset from the following link:\n",
        "https://anonymous.4open.science/api/repo/EdgeCatBSPDataset-EDED/file/hsr_extended_dataset.zip\n",
        "\n",
        "Unzip the dataset after downloading.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You may need to adjust the paths in the \"HSR_datasets\" field with respect to where you have saved the dataset.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e-V8D08jFR0-"
      },
      "source": [
        "## Evaluation of HSR Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HSR DATASET PART 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "lemmxBLrFQ0U",
        "outputId": "aac09a52-fa17-42a7-9b2d-ffdc835d6ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "                 0\n",
            "count  3319.000000\n",
            "mean      1.837007\n",
            "std       0.520614\n",
            "min       0.000000\n",
            "25%       1.716181\n",
            "50%       2.119993\n",
            "75%       2.160004\n",
            "max       2.402126\n",
            "100:  99.57818620066286\n",
            "200:  98.88520638746611\n",
            "500:  95.26965953600482\n",
            "1000:  90.05724615848148\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"HSR_Extended_4_0\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "max_achievable(HSR_seq_dict, HSR_seq_dict_checker, HSR_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(336299, 6, 4)\n"
          ]
        }
      ],
      "source": [
        "print(HSR_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNNG0_fNJ80_",
        "outputId": "5b0d5a3e-603f-4145-e5fc-70b7dc148fdc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-26 23:15:58.693180: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-06-26 23:15:58.702098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-06-26 23:15:58.706200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-06-26 23:15:59.426525: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-06-26 23:15:59.431747: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-06-26 23:15:59.445963: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10510/10510 [==============================] - 76s 7ms/step\n",
            "Handover Count: 3319\n",
            "                 0\n",
            "count  3283.000000\n",
            "mean      1.668875\n",
            "std       0.591842\n",
            "min       0.037904\n",
            "25%       1.315791\n",
            "50%       1.920797\n",
            "75%       2.158667\n",
            "max       2.402126\n",
            "100:  98.3127448026514\n",
            "200:  97.49924676107261\n",
            "500:  92.43748116902681\n",
            "1000:  82.13317264236217\n",
            "10510/10510 [==============================] - 69s 7ms/step\n",
            "Handover Count: 3319\n",
            "                 0\n",
            "count  3302.000000\n",
            "mean      1.665245\n",
            "std       0.597766\n",
            "min       0.000000\n",
            "25%       1.308395\n",
            "50%       1.921101\n",
            "75%       2.158673\n",
            "max       2.402126\n",
            "100:  98.583910816511\n",
            "200:  97.77041277493221\n",
            "500:  92.6785176257909\n",
            "1000:  82.46459777041278\n",
            "10510/10510 [==============================] - 67s 6ms/step\n",
            "Handover Count: 3319\n",
            "                 0\n",
            "count  3305.000000\n",
            "mean      1.664281\n",
            "std       0.598938\n",
            "min       0.000000\n",
            "25%       1.300038\n",
            "50%       1.920041\n",
            "75%       2.158673\n",
            "max       2.402126\n",
            "100:  98.6140403736065\n",
            "200:  97.80054233202772\n",
            "500:  92.6785176257909\n",
            "1000:  82.52485688460379\n",
            "10510/10510 [==============================] - 66s 6ms/step\n",
            "Handover Count: 3319\n",
            "                 0\n",
            "count  3308.000000\n",
            "mean      1.662772\n",
            "std       0.600759\n",
            "min       0.000000\n",
            "25%       1.290523\n",
            "50%       1.920022\n",
            "75%       2.158665\n",
            "max       2.402126\n",
            "100:  98.6140403736065\n",
            "200:  97.80054233202772\n",
            "500:  92.6785176257909\n",
            "1000:  82.52485688460379\n",
            "10510/10510 [==============================] - 65s 6ms/step\n",
            "Handover Count: 3319\n",
            "                 0\n",
            "count  3308.000000\n",
            "mean      1.662772\n",
            "std       0.600759\n",
            "min       0.000000\n",
            "25%       1.290523\n",
            "50%       1.920022\n",
            "75%       2.158665\n",
            "max       2.402126\n",
            "100:  98.6140403736065\n",
            "200:  97.80054233202772\n",
            "500:  92.6785176257909\n",
            "1000:  82.52485688460379\n"
          ]
        }
      ],
      "source": [
        "for i in range(1,6):\n",
        "  output_fname = \"HSR_0\" + str(i) + \"_earliest.txt\"\n",
        "  get_top_n_results(model_eval, HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig, HSR_seq_dict_checker, i, output_fname)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HSR DATASET PART 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "10587/10587 [==============================] - 64s 6ms/step\n",
            "Handover Count: 3367\n",
            "                 0\n",
            "count  3330.000000\n",
            "mean      1.693197\n",
            "std       0.580484\n",
            "min       0.000000\n",
            "25%       1.322658\n",
            "50%       1.960011\n",
            "75%       2.158555\n",
            "max       2.402126\n",
            "100:  98.42589842589842\n",
            "200:  97.2081972081972\n",
            "500:  92.96109296109296\n",
            "1000:  83.6055836055836\n",
            "10587/10587 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3367\n",
            "                 0\n",
            "count  3351.000000\n",
            "mean      1.689706\n",
            "std       0.585409\n",
            "min       0.000000\n",
            "25%       1.321960\n",
            "50%       1.959989\n",
            "75%       2.158420\n",
            "max       2.402126\n",
            "100:  98.72289872289872\n",
            "200:  97.5051975051975\n",
            "500:  93.34719334719335\n",
            "1000:  84.08078408078407\n",
            "10587/10587 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3367\n",
            "                 0\n",
            "count  3353.000000\n",
            "mean      1.689523\n",
            "std       0.585765\n",
            "min       0.000000\n",
            "25%       1.322165\n",
            "50%       1.959989\n",
            "75%       2.158415\n",
            "max       2.402126\n",
            "100:  98.72289872289872\n",
            "200:  97.5051975051975\n",
            "500:  93.37689337689338\n",
            "1000:  84.16988416988417\n",
            "10587/10587 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3367\n",
            "                 0\n",
            "count  3357.000000\n",
            "mean      1.687580\n",
            "std       0.588123\n",
            "min       0.000000\n",
            "25%       1.321472\n",
            "50%       1.959922\n",
            "75%       2.158414\n",
            "max       2.402126\n",
            "100:  98.75259875259876\n",
            "200:  97.53489753489754\n",
            "500:  93.37689337689338\n",
            "1000:  84.16988416988417\n",
            "10587/10587 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3367\n",
            "                 0\n",
            "count  3357.000000\n",
            "mean      1.687580\n",
            "std       0.588123\n",
            "min       0.000000\n",
            "25%       1.321472\n",
            "50%       1.959922\n",
            "75%       2.158414\n",
            "max       2.402126\n",
            "100:  98.75259875259876\n",
            "200:  97.53489753489754\n",
            "500:  93.37689337689338\n",
            "1000:  84.16988416988417\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"HSR_Extended_4_1\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "for i in range(1,6):\n",
        "  output_fname = \"HSR_1\" + str(i) + \"_earliest.txt\"\n",
        "  get_top_n_results(model_eval, HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig, HSR_seq_dict_checker, i, output_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "                 0\n",
            "count  3367.000000\n",
            "mean      1.840130\n",
            "std       0.519271\n",
            "min       0.000000\n",
            "25%       1.722562\n",
            "50%       2.120002\n",
            "75%       2.160002\n",
            "max       2.402126\n",
            "100:  99.67329967329968\n",
            "200:  98.6040986040986\n",
            "500:  95.27769527769527\n",
            "1000:  90.08019008019008\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"HSR_Extended_4_1\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "max_achievable(HSR_seq_dict, HSR_seq_dict_checker, HSR_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HSR DATASET PART 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "10530/10530 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3327\n",
            "                 0\n",
            "count  3282.000000\n",
            "mean      1.647124\n",
            "std       0.602567\n",
            "min       0.000000\n",
            "25%       1.214149\n",
            "50%       1.915754\n",
            "75%       2.158024\n",
            "max       2.207901\n",
            "100:  97.74571686203787\n",
            "200:  96.99428914938383\n",
            "500:  91.64412383528705\n",
            "1000:  80.64322212203187\n",
            "10530/10530 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3327\n",
            "                 0\n",
            "count  3303.000000\n",
            "mean      1.642268\n",
            "std       0.609611\n",
            "min       0.000000\n",
            "25%       1.206427\n",
            "50%       1.913940\n",
            "75%       2.157989\n",
            "max       2.207901\n",
            "100:  98.04628794709949\n",
            "200:  97.23474601743312\n",
            "500:  91.85452359483017\n",
            "1000:  80.94379320709348\n",
            "10530/10530 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3327\n",
            "                 0\n",
            "count  3310.000000\n",
            "mean      1.639280\n",
            "std       0.613292\n",
            "min       0.000000\n",
            "25%       1.200368\n",
            "50%       1.913799\n",
            "75%       2.157975\n",
            "max       2.207901\n",
            "100:  98.04628794709949\n",
            "200:  97.23474601743312\n",
            "500:  91.85452359483017\n",
            "1000:  81.0039074241058\n",
            "10530/10530 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3327\n",
            "                 0\n",
            "count  3311.000000\n",
            "mean      1.638785\n",
            "std       0.613861\n",
            "min       0.000000\n",
            "25%       1.200221\n",
            "50%       1.913675\n",
            "75%       2.157975\n",
            "max       2.207901\n",
            "100:  98.04628794709949\n",
            "200:  97.23474601743312\n",
            "500:  91.85452359483017\n",
            "1000:  81.0039074241058\n",
            "10530/10530 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3327\n",
            "                 0\n",
            "count  3311.000000\n",
            "mean      1.638785\n",
            "std       0.613861\n",
            "min       0.000000\n",
            "25%       1.200221\n",
            "50%       1.913675\n",
            "75%       2.157975\n",
            "max       2.207901\n",
            "100:  98.04628794709949\n",
            "200:  97.23474601743312\n",
            "500:  91.85452359483017\n",
            "1000:  81.0039074241058\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"HSR_Extended_4_2\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "for i in range(1,6):\n",
        "  output_fname = \"HSR_2\" + str(i) + \"_earliest.txt\"\n",
        "  get_top_n_results(model_eval, HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig, HSR_seq_dict_checker, i, output_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "                 0\n",
            "count  3327.000000\n",
            "mean      1.837313\n",
            "std       0.526419\n",
            "min       0.000000\n",
            "25%       1.720002\n",
            "50%       2.120003\n",
            "75%       2.160001\n",
            "max       2.237871\n",
            "100:  99.42891493838293\n",
            "200:  98.67748722572888\n",
            "500:  95.28103396453261\n",
            "1000:  89.26961226330027\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"HSR_Extended_4_2\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "max_achievable(HSR_seq_dict, HSR_seq_dict_checker, HSR_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HSR DATASET PART 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "10576/10576 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3359\n",
            "                 0\n",
            "count  3314.000000\n",
            "mean      1.666375\n",
            "std       0.588720\n",
            "min       0.000000\n",
            "25%       1.280015\n",
            "50%       1.920009\n",
            "75%       2.158186\n",
            "max       2.210000\n",
            "100:  98.09467103304554\n",
            "200:  97.38017267043763\n",
            "500:  92.4679964275082\n",
            "1000:  81.89937481393271\n",
            "10576/10576 [==============================] - 67s 6ms/step\n",
            "Handover Count: 3359\n",
            "                 0\n",
            "count  3335.000000\n",
            "mean      1.664908\n",
            "std       0.592158\n",
            "min       0.000000\n",
            "25%       1.280015\n",
            "50%       1.920001\n",
            "75%       2.158183\n",
            "max       2.210000\n",
            "100:  98.48169097945816\n",
            "200:  97.73742185174159\n",
            "500:  92.76570407859482\n",
            "1000:  82.49479011610599\n",
            "10576/10576 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3359\n",
            "                 0\n",
            "count  3339.000000\n",
            "mean      1.663237\n",
            "std       0.594219\n",
            "min       0.000000\n",
            "25%       1.280010\n",
            "50%       1.919999\n",
            "75%       2.158176\n",
            "max       2.210000\n",
            "100:  98.48169097945816\n",
            "200:  97.73742185174159\n",
            "500:  92.79547484370349\n",
            "1000:  82.52456088121465\n",
            "10576/10576 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3359\n",
            "                 0\n",
            "count  3342.000000\n",
            "mean      1.662150\n",
            "std       0.595924\n",
            "min       0.000000\n",
            "25%       1.280010\n",
            "50%       1.919998\n",
            "75%       2.158170\n",
            "max       2.210000\n",
            "100:  98.48169097945816\n",
            "200:  97.73742185174159\n",
            "500:  92.79547484370349\n",
            "1000:  82.52456088121465\n",
            "10576/10576 [==============================] - 62s 6ms/step\n",
            "Handover Count: 3359\n",
            "                 0\n",
            "count  3344.000000\n",
            "mean      1.661156\n",
            "std       0.597130\n",
            "min       0.000000\n",
            "25%       1.280003\n",
            "50%       1.919997\n",
            "75%       2.158169\n",
            "max       2.210000\n",
            "100:  98.48169097945816\n",
            "200:  97.73742185174159\n",
            "500:  92.79547484370349\n",
            "1000:  82.52456088121465\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"HSR_Extended_4_3\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "for i in range(1,6):\n",
        "  output_fname = \"HSR_3\" + str(i) + \"_earliest.txt\"\n",
        "  get_top_n_results(model_eval, HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig, HSR_seq_dict_checker, i, output_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "                 0\n",
            "count  3359.000000\n",
            "mean      1.832966\n",
            "std       0.521397\n",
            "min       0.000000\n",
            "25%       1.693121\n",
            "50%       2.119296\n",
            "75%       2.160001\n",
            "max       2.210000\n",
            "100:  99.61298005358738\n",
            "200:  98.92825245608812\n",
            "500:  95.44507293837452\n",
            "1000:  89.66954450729384\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"HSR_Extended_4_3\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "max_achievable(HSR_seq_dict, HSR_seq_dict_checker, HSR_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HSR DATASET PART 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "10689/10689 [==============================] - 63s 6ms/step\n",
            "Handover Count: 3312\n",
            "                 0\n",
            "count  3260.000000\n",
            "mean      1.632724\n",
            "std       0.600332\n",
            "min       0.000000\n",
            "25%       1.199997\n",
            "50%       1.877832\n",
            "75%       2.157883\n",
            "max       2.204813\n",
            "100:  97.52415458937197\n",
            "200:  96.46739130434783\n",
            "500:  92.11956521739131\n",
            "1000:  80.012077294686\n",
            "10689/10689 [==============================] - 63s 6ms/step\n",
            "Handover Count: 3312\n",
            "                 0\n",
            "count  3279.000000\n",
            "mean      1.632893\n",
            "std       0.603006\n",
            "min       0.000000\n",
            "25%       1.200033\n",
            "50%       1.877886\n",
            "75%       2.157883\n",
            "max       2.204813\n",
            "100:  97.88647342995169\n",
            "200:  96.82971014492753\n",
            "500:  92.45169082125604\n",
            "1000:  80.58574879227052\n",
            "10689/10689 [==============================] - 63s 6ms/step\n",
            "Handover Count: 3312\n",
            "                 0\n",
            "count  3282.000000\n",
            "mean      1.631804\n",
            "std       0.604363\n",
            "min       0.000000\n",
            "25%       1.200015\n",
            "50%       1.877880\n",
            "75%       2.157882\n",
            "max       2.204813\n",
            "100:  97.91666666666666\n",
            "200:  96.85990338164251\n",
            "500:  92.45169082125604\n",
            "1000:  80.61594202898551\n",
            "10689/10689 [==============================] - 63s 6ms/step\n",
            "Handover Count: 3312\n",
            "                 0\n",
            "count  3284.000000\n",
            "mean      1.630847\n",
            "std       0.605548\n",
            "min       0.000000\n",
            "25%       1.200013\n",
            "50%       1.877870\n",
            "75%       2.157883\n",
            "max       2.204813\n",
            "100:  97.91666666666666\n",
            "200:  96.85990338164251\n",
            "500:  92.45169082125604\n",
            "1000:  80.61594202898551\n",
            "10689/10689 [==============================] - 63s 6ms/step\n",
            "Handover Count: 3312\n",
            "                 0\n",
            "count  3284.000000\n",
            "mean      1.630847\n",
            "std       0.605548\n",
            "min       0.000000\n",
            "25%       1.200013\n",
            "50%       1.877870\n",
            "75%       2.157883\n",
            "max       2.204813\n",
            "100:  97.91666666666666\n",
            "200:  96.85990338164251\n",
            "500:  92.45169082125604\n",
            "1000:  80.61594202898551\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"HSR_Extended_4_4\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "for i in range(1,6):\n",
        "  output_fname = \"HSR_4\" + str(i) + \"_earliest.txt\"\n",
        "  get_top_n_results(model_eval, HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig, HSR_seq_dict_checker, i, output_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "                 0\n",
            "count  3312.000000\n",
            "mean      1.833156\n",
            "std       0.528459\n",
            "min       0.000000\n",
            "25%       1.717764\n",
            "50%       2.119992\n",
            "75%       2.160004\n",
            "max       2.237871\n",
            "100:  99.2451690821256\n",
            "200:  98.52053140096618\n",
            "500:  95.44082125603865\n",
            "1000:  89.58333333333334\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"HSR_Extended_4_4\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "max_achievable(HSR_seq_dict, HSR_seq_dict_checker, HSR_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HSR FineGrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "507/507 [==============================] - 4s 8ms/step\n",
            "Handover Count: 405\n",
            "                0\n",
            "count  370.000000\n",
            "mean     0.945824\n",
            "std      0.530116\n",
            "min      0.000000\n",
            "25%      0.485334\n",
            "50%      0.957867\n",
            "75%      1.346004\n",
            "max      2.287975\n",
            "100:  84.19753086419753\n",
            "200:  81.48148148148148\n",
            "500:  67.90123456790124\n",
            "1000:  44.44444444444444\n",
            "507/507 [==============================] - 3s 6ms/step\n",
            "Handover Count: 405\n",
            "                0\n",
            "count  396.000000\n",
            "mean     0.955050\n",
            "std      0.538690\n",
            "min      0.000000\n",
            "25%      0.517519\n",
            "50%      0.959215\n",
            "75%      1.360547\n",
            "max      2.287975\n",
            "100:  89.62962962962962\n",
            "200:  86.66666666666667\n",
            "500:  73.58024691358025\n",
            "1000:  48.148148148148145\n",
            "507/507 [==============================] - 3s 7ms/step\n",
            "Handover Count: 405\n",
            "                0\n",
            "count  399.000000\n",
            "mean     0.977261\n",
            "std      0.534329\n",
            "min      0.000000\n",
            "25%      0.560897\n",
            "50%      1.000748\n",
            "75%      1.368553\n",
            "max      2.287975\n",
            "100:  90.61728395061729\n",
            "200:  87.90123456790123\n",
            "500:  76.29629629629629\n",
            "1000:  50.123456790123456\n",
            "507/507 [==============================] - 3s 6ms/step\n",
            "Handover Count: 405\n",
            "                0\n",
            "count  401.000000\n",
            "mean     0.977393\n",
            "std      0.535390\n",
            "min      0.000000\n",
            "25%      0.554396\n",
            "50%      1.000748\n",
            "75%      1.368926\n",
            "max      2.287975\n",
            "100:  91.11111111111111\n",
            "200:  88.39506172839506\n",
            "500:  76.29629629629629\n",
            "1000:  50.37037037037037\n",
            "507/507 [==============================] - 3s 6ms/step\n",
            "Handover Count: 405\n",
            "                0\n",
            "count  401.000000\n",
            "mean     0.977393\n",
            "std      0.535390\n",
            "min      0.000000\n",
            "25%      0.554396\n",
            "50%      1.000748\n",
            "75%      1.368926\n",
            "max      2.287975\n",
            "100:  91.11111111111111\n",
            "200:  88.39506172839506\n",
            "500:  76.29629629629629\n",
            "1000:  50.37037037037037\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"../with_RAW_CNXT/HSR_August_Dataset/\", \"../with_RAW_CNXT/HSR_July_Dataset/\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "for i in range(1,6):\n",
        "  output_fname = \"HSR_FG\" + str(i) + \"_earliest.txt\"\n",
        "  get_top_n_results(model_eval, HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig, HSR_seq_dict_checker, i, output_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFF COUNT CHECK: 0\n",
            "                0\n",
            "count  405.000000\n",
            "mean     1.009009\n",
            "std      0.543597\n",
            "min      0.000000\n",
            "25%      0.562871\n",
            "50%      1.073573\n",
            "75%      1.401144\n",
            "max      2.287975\n",
            "100:  92.8395061728395\n",
            "200:  90.12345679012346\n",
            "500:  77.53086419753087\n",
            "1000:  54.32098765432099\n"
          ]
        }
      ],
      "source": [
        "HSR_datasets = [\"../with_RAW_CNXT/HSR_August_Dataset/\", \"../with_RAW_CNXT/HSR_July_Dataset/\"]\n",
        "\n",
        "_, _, HSR_seq_dict_checker, HSR_seq_dict_checker_orig = load_dataset(HSR_datasets, 6)\n",
        "HSR_features, HSR_labels, HSR_seq_dict, HSR_seq_dict_orig = load_dataset_padding(HSR_datasets, 6)\n",
        "\n",
        "max_achievable(HSR_seq_dict, HSR_seq_dict_checker, HSR_labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EqBjxAl4vp90",
        "DEOuOn-E3dHP",
        "bs77xf4PWpjo",
        "EzQpFt8hFKX8",
        "e-V8D08jFR0-",
        "VHtnywK2LV1I",
        "9yWXOq69Mgbb",
        "sHp6aot-C3us"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
